---
title: Put it to the test
date: 2019-04-11 00:00:00 +0200
header_image_path: /uploads/boxed-water-is-better-1464047-unsplash.jpg
author: Jesse van der Pluijm
author_link: 'https://jessevdp.nl'
is_featured: true
---

The results of Swiss Post’s public intrusion test of the design of its electronic voting system, which offered big financial prizes for those able to identify its vulnerabilities, and which I mentioned a couple of months ago, has revealed several important weaknesses that have forced the company to suspend its use in elections scheduled for May 19.

One can only wonder as to what would have happened if the company had not invited hackers from around the world to test the security of the system, particularly at a time when we are only just beginning to understand the scale and scope of digital interference in electoral processes.

More and more companies are understanding the strategic importance of putting their computer systems to the test. Microsoft has just announced a revamp of its bug bounty program in association with HackerOne, the platform run by M&aring;rten Mickos that connects companies with security researchers and coordinates work and payments based on what is discovered, so as to make their programs more attractive and thus obtain greater security guarantees for their products. Other major companies, such as GM, have been working like this for more than three years. Dropbox, which has also spent time working with the company, discovered 264 vulnerabilities and paid $319,300 in prizes after a recent one-day marathon in Singapore.

As the old saying goes, the worst vulnerability is the one yet to be discovered. These days, more than ever, all companies are at risk and no development team will ever be able to cover every possible security weakness: Linus’s Law, named after Linus Torvalds, states that

“given enough eyeballs, all bugs are shallow,”

or to put it more formally: “given a large enough beta-tester and co-developer base, almost every problem will be characterized quickly and the fix obvious to someone.”

However you look at it, the simple truth is that in your company there are information technology vulnerabilities that can be exploited maliciously, and that no doubt applies to the university I work at as well: a recent survey of British universities showed that a group of hackers found critical vulnerabilities in all of them in less than two hours, publishing the result — of course — in the form of an academic paper. It seems pretty obvious that when it comes to challenging security, a university website is hardly the benchmark.

In any event, there is probably no such thing as total security, as the legendary Gene Spafford once said:

“The only truly secure system is one that is powered off, cast in a block of concrete and sealed in a lead-lined room with armed guards — and even then I have my doubts.”

Without going that far (and which would make your systems obviously impossible to use), if you run a business or any other organization, you should at least consider doing everything possible to locate and correct as many failures as you can to avoid joining the club of security systems that can be breached in less than two hours. At the very least, you need to know that you did everything humanly possible to prevent someone from exploiting an extremely obvious vulnerability, such as a beginner’s mistake. Okay, we accept that total security does not exist, but that doesn’t mean throwing in the towel: at least give it a go.

Bug bounty programs are an excellent way of dealing with security issues: ask well-selected external talent to look for all possible vulnerabilities in your company’s systems, and pay them for it, because security, like everything else, costs money. If you don’t find those vulnerabilities, others will, and probably not with the best intentions. If you don’t think it’s worth spending the money or if you don’t think anybody is interested in prizing open your system’s vulnerabilities, then you clearly have yet to understand how security works in today’s world.